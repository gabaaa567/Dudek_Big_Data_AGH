{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fe8390b-d3e0-4630-b7f4-c9ad4e8ca641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#display(dbutils.fs.ls(\"/FileStore/tables/\"))\n",
    "df = spark.read.csv(\"dbfs:/FileStore/tables/2011_12_07.csv\", header=True, inferSchema=True)\n",
    "#display(df)\n",
    "\n",
    "# ZADANIE 1\n",
    "# fill - fill i fillna zwaraca to samo, chodzi o zastąpienie wartosci null\n",
    "df_fill = df.na.fill({\"CustomerID\": 0})\n",
    "#display(df_fill)\n",
    "\n",
    "\n",
    "# explode - rozbijanie tablicy na soobne kolumny - TO POLECENIE NIE PRZEJDZIE! - nie mam wsrod tych danych kolumny typu array, np. : skills =  [php, R]\n",
    "#df_exploded = df.withColumn(\"cou\", explode(\"Description\")).drop(\"Description\")\n",
    "#display(df_exploded)\n",
    "\n",
    "\n",
    "# drop - usniecie wierszy z null\n",
    "df_drop = df.dropna(subset=[\"Description\"])\n",
    "#display(df_drop)\n",
    "\n",
    "\n",
    "# regexp_replace - służy do zamiany fragmentów tekstu w kolumnach DataFrame na podstawie wyrażeń regularnych (regex)\n",
    "df_regex = df.withColumn(\"col_regex\", regexp_replace(col(\"Country\"), r\"\\w{3}$\", \"XXX\"))\n",
    "#display(df_regex)\n",
    "\n",
    "\n",
    "# regexp_extract - służy do wyciągania fragmentów tekstu z kolumny na podstawie wyrażenia regularnego (regex\n",
    "df_reg2 = df.withColumn(\"invoice_type\",regexp_extract(col(\"InvoiceNo\"), r\"^([A-Z])\", 1))  # Pierwsza litera (S, C, itp.)\n",
    "#display(df_reg2)\n",
    "\n",
    "\n",
    "# ifnull - \n",
    "df_ifnull = df.withColumn(\"customerid_filled\", expr(\"ifnull(CustomerID, 0)\"))  # wstaw 0 gdy CustomerID jest null)\n",
    "#display(df_ifnull)\n",
    "\n",
    "\n",
    "#nullif - zwraca null gdy wartosci sa rowne\n",
    "df_nullIf = df.withColumn(\"uk_null\", expr(\"nullIf(Country, 'United Kingdom')\"))  # NULL, jeśli kraj to uk\n",
    "#display(df_nullIf)\n",
    "\n",
    "\n",
    "# replace - zamiana okreslonych wartosci na inne\n",
    "df_replace = df.replace(\"Germany\", \"X\")\n",
    "#display(df_replace)\n",
    "\n",
    "\n",
    "# array_contains - służy do sprawdzania, czy tablica (kolumna typu Array) zawiera określoną wartość. Zwraca True, jeśli wartość istnieje w tablicy, lub False, jeśli nie.\n",
    "#stworzymy najpiewr tablice\n",
    "df_with_array = df.withColumn(\"product_info_array\", array(col(\"StockCode\"), col(\"Description\")))\n",
    "#display(df_with_array.select(\"product_info_array\"))\n",
    "\n",
    "df_with_flag = df_with_array.withColumn(\"contains_check\", array_contains(col(\"product_info_array\"), \"check\"))\n",
    "#display(df_with_flag.filter(col(\"contains_check\") == True))\n",
    "\n",
    "\n",
    "# PRZYKLAD B\n",
    "c_stats = df.groupBy(\"Country\").agg(\n",
    "    sum(\"Quantity\").alias(\"total_quantity\"),       #suma zamowien\n",
    "    avg(\"UnitPrice\").alias(\"avg_price\"),          #srednia cenka produktu\n",
    "    count(\"*\").alias(\"order_count\")               #liczba zamowien\n",
    ").orderBy(\"total_quantity\", ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb0118af-ee0f-4d73-8f15-ca510a78a873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## ZADNIE 2\n",
    "# funckja UDF - mechanizm ktory pozwala na stworzenie wlasnych, niestandardowych funkcji \n",
    "#dla double; pandas\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(DoubleType())\n",
    "def calculate_discount(price: pd.Series, rating: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    oblicza zniezke na produkt procentowo\n",
    "    - ceny (im wyższa cena, tym większa zniżka)\n",
    "    - oceny (im wyższa ocena, tym większa zniżka)\n",
    "    \n",
    "    znizka od 0 do 20%\n",
    "    - 5% podstawowej zniżki\n",
    "    - dodatkowo do 10% za cenę (1% za każde 100 jednostek ceny)\n",
    "    - dodatkowo do 5% za ocenę (1% za każdy punkt oceny powyżej 3)\n",
    "    \"\"\"\n",
    "    base_discount = 5\n",
    "    price_discount = (price / 100).clip(upper=10)\n",
    "    rating_discount = ((rating - 3) * 1).clip(lower=0, upper=5)\n",
    "    \n",
    "    total_discount = base_discount + price_discount + rating_discount\n",
    "    return total_discount.clip(upper=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e26847c-d1f3-4bd3-9234-11a4dcacee54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ZADANIE 2\n",
    "# UDF - dla stringow\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "@udf(StringType())\n",
    "def format_product_name(name: str, category: str) -> str:\n",
    "    \"\"\"\n",
    "    formatowanie nazwy i kategorii produktu\n",
    "    - minus biale znaki na poczatku i koncu\n",
    "    - zmiana na male litery\n",
    "    - Dodaje kategorię w nawiasach jeśli nie jest pusta\n",
    "    - wielokrotne spacje na pojedyncze\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        return None\n",
    "        \n",
    "    name_clean = ' '.join(name.strip().lower().split())\n",
    "    category_clean = ' '.join(category.strip().lower().split()) if category else ''\n",
    "    \n",
    "    if category_clean:\n",
    "        return f\"{name_clean} ({category_clean})\"\n",
    "    return name_clean"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "lab4",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}